#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•OpenAIå®¢æˆ·ç«¯åŠŸèƒ½
"""

import asyncio
import os
from pathlib import Path

# æ·»åŠ backendç›®å½•åˆ°Pythonè·¯å¾„
import sys
backend_dir = Path(__file__).parent / "backend"
sys.path.insert(0, str(backend_dir))

from services.openai_client import OpenAIClient
from utils.env import load_env_vars

async def test_openai_client():
    """æµ‹è¯•OpenAIå®¢æˆ·ç«¯åŸºæœ¬åŠŸèƒ½"""
    print("å¼€å§‹æµ‹è¯•OpenAIå®¢æˆ·ç«¯...")
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_env_vars()
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    api_key = os.getenv("OPENAI_API_KEY")
    base_url = os.getenv("OPENAI_BASE_URL")
    model = os.getenv("DEFAULT_MODEL")
    
    print(f"API Key: {api_key[:10]}..." if api_key else "API Key: æœªè®¾ç½®")
    print(f"Base URL: {base_url}")
    print(f"Model: {model}")
    
    if not api_key:
        print("âŒ OPENAI_API_KEY æœªè®¾ç½®ï¼Œæ— æ³•è¿›è¡Œæµ‹è¯•")
        return False
    
    try:
        # åˆ›å»ºå®¢æˆ·ç«¯
        client = OpenAIClient()
        print("âœ… OpenAIå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•ç®€å•çš„æ–‡æœ¬ç”Ÿæˆ
        print("\næµ‹è¯•æ–‡æœ¬ç”Ÿæˆ...")
        response = await client.generate(
            prompt="è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½",
            max_tokens=100,
            temperature=0.7
        )
        
        if response and "choices" in response:
            content = client.extract_text_from_response(response)
            print(f"âœ… æ–‡æœ¬ç”ŸæˆæˆåŠŸ: {content[:100]}...")
            return True
        else:
            print(f"âŒ æ–‡æœ¬ç”Ÿæˆå¤±è´¥: {response}")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

async def test_book_analysis():
    """æµ‹è¯•ä¹¦ç±åˆ†æç›¸å…³åŠŸèƒ½"""
    print("\næµ‹è¯•ä¹¦ç±åˆ†æåŠŸèƒ½...")
    
    try:
        client = OpenAIClient()
        
        # æ¨¡æ‹Ÿä¹¦ç±å†…å®¹
        book_content = """
        ã€Šäººå·¥æ™ºèƒ½ç®€å²ã€‹æ˜¯ä¸€æœ¬ä»‹ç»äººå·¥æ™ºèƒ½å‘å±•å†ç¨‹çš„ä¹¦ç±ã€‚
        æœ¬ä¹¦ä»å›¾çµæµ‹è¯•å¼€å§‹ï¼Œè®²è¿°äº†äººå·¥æ™ºèƒ½ä»è¯ç”Ÿåˆ°ç°åœ¨çš„å‘å±•å†ç¨‹ã€‚
        ä¹¦ä¸­è¯¦ç»†ä»‹ç»äº†æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€ç¥ç»ç½‘ç»œç­‰æ ¸å¿ƒæŠ€æœ¯ã€‚
        """
        
        # æµ‹è¯•ä¹¦ç±æ‘˜è¦ç”Ÿæˆ
        summary_prompt = """
        è¯·ä¸ºä»¥ä¸‹ä¹¦ç±å†…å®¹ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ‘˜è¦ï¼ŒåŒ…æ‹¬ä¸»è¦è§‚ç‚¹å’Œæ ¸å¿ƒå†…å®¹ï¼š
        
        {content}
        
        è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
        - title: ä¹¦ç±æ ‡é¢˜
        - main_points: ä¸»è¦è§‚ç‚¹åˆ—è¡¨
        - summary: ç®€è¦æ€»ç»“
        """
        
        response = await client.generate(
            prompt=summary_prompt.format(content=book_content),
            max_tokens=500,
            temperature=0.3,
            system_message="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¹¦ç±åˆ†æå¸ˆï¼Œæ“…é•¿æå–ä¹¦ç±çš„æ ¸å¿ƒå†…å®¹å’Œè¦ç‚¹ã€‚"
        )
        
        if response and "choices" in response:
            content = client.extract_text_from_response(response)
            print(f"âœ… ä¹¦ç±æ‘˜è¦ç”ŸæˆæˆåŠŸ: {content[:200]}...")
            return True
        else:
            print(f"âŒ ä¹¦ç±æ‘˜è¦ç”Ÿæˆå¤±è´¥: {response}")
            return False
            
    except Exception as e:
        print(f"âŒ ä¹¦ç±åˆ†ææµ‹è¯•å¤±è´¥: {str(e)}")
        return False

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 50)
    print("OpenAIå®¢æˆ·ç«¯åŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    
    # åŸºæœ¬åŠŸèƒ½æµ‹è¯•
    basic_test = await test_openai_client()
    
    # ä¹¦ç±åˆ†æåŠŸèƒ½æµ‹è¯•
    analysis_test = await test_book_analysis()
    
    print("\n" + "=" * 50)
    print("æµ‹è¯•ç»“æœæ±‡æ€»:")
    print(f"åŸºæœ¬åŠŸèƒ½æµ‹è¯•: {'âœ… é€šè¿‡' if basic_test else 'âŒ å¤±è´¥'}")
    print(f"ä¹¦ç±åˆ†ææµ‹è¯•: {'âœ… é€šè¿‡' if analysis_test else 'âŒ å¤±è´¥'}")
    
    if basic_test and analysis_test:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼OpenAIå®¢æˆ·ç«¯é…ç½®æ­£ç¡®ï¼ŒåŠŸèƒ½æ­£å¸¸ã€‚")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œç½‘ç»œè¿æ¥ã€‚")
    
    print("=" * 50)

if __name__ == "__main__":
    asyncio.run(main())